#!/usr/bin/env python

import logging
from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.ensemble import AdaBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor

ESTIMATOR = AdaBoostRegressor

logging.basicConfig(
    datefmt="%Y-%m-%dT%H:%M:%S",
    level=logging.DEBUG,
    format="[%(asctime)s] %(levelname)8s %(message)s",
)


def evaluate(model: ESTIMATOR, X_test: np.ndarray, y_test: np.ndarray) -> None:
    logging.info("Score: %s", model.score(X_test, y_test))


def load() -> pd.DataFrame:
    path = Path("data/diamonds.csv")
    logging.info("Loading data: %s", path)
    return pd.read_csv(path)


def prep(X_train: np.ndarray, X_test: np.ndarray) -> list[np.ndarray]:
    logging.info("Preparing samples")
    return [StandardScaler().fit_transform(a) for a in (X_train, X_test)]


def split(data: pd.DataFrame) -> list[np.ndarray]:
    logging.info("Splitting data")
    X, y = data.drop(columns=["price"]), data["price"]
    return [a.to_numpy() for a in train_test_split(X, y)]


def train(X_train: np.ndarray, y_train: np.ndarray) -> ESTIMATOR:
    logging.info("Training model")
    model = ESTIMATOR(
        estimator=DecisionTreeRegressor(max_depth=8),
        learning_rate=0.5,
        n_estimators=10,
    )
    model.fit(X_train, y_train)
    return model


logging.info("AdaBoost Regressor")
data = load()
X_train, X_test, y_train, y_test = split(data)
X_train, X_test = prep(X_train, X_test)
model = train(X_train, y_train)
evaluate(model, X_test, y_test)

# Scaling seems to have little/no effect.
# Specifying max_depth on DecisionTreeRegressor: 88% -> 98%
